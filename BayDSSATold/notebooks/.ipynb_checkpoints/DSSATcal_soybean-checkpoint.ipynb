{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0f9b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T10:16:23.534764Z",
     "start_time": "2023-03-04T10:16:23.373142Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'WaterBalance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mDSSATTools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh3\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mWaterBalance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSWconnect\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mduckdb\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gp_minimize\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'WaterBalance'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import DSSATTools\n",
    "import h3\n",
    "from WaterBalance import CSWconnect\n",
    "import duckdb\n",
    "from skopt import gp_minimize\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Extract\n",
    "def getFields(crop: str, regn: str) -> pd.DataFrame:\n",
    "   \n",
    "    query_hss = f\"\"\"\n",
    "    SELECT \n",
    "      FIELD_NAME, commercialName, createdBrand, createdMG, protocolNumber, FIELD_Country, FIELD_field_latitude,\n",
    "      FIELD_field_longitude, FIELD_plantingDate, FIELD_harvestDate, OBS_observationRefCd, OBS_numValue,  \n",
    "      plot_id, QC_Flag, field_id, FIELD_mac, FIELD_mic, FIELD_uniqueName\n",
    "    FROM \n",
    "      latam_datasets.hss_{regn}_current_{crop} \n",
    "    WHERE \n",
    "      OBS_observationRefCd in ('YLD','MAT')\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "      FIELD_NAME, commercialName, createdBrand, createdMG, protocolNumber, FIELD_Country, FIELD_field_latitude,\n",
    "      FIELD_field_longitude, FIELD_plantingDate, FIELD_harvestDate, OBS_observationRefCd, OBS_numValue,  \n",
    "      plot_id, QC_Flag, field_id, FIELD_mac, FIELD_mic, FIELD_uniqueName\n",
    "    FROM \n",
    "      latam_datasets.hss_{regn}_historical_{crop} \n",
    "    WHERE \n",
    "      OBS_observationRefCd in ('YLD','MAT')\n",
    "    \"\"\"\n",
    "\n",
    "    return CSWconnect('bcs-market-dev-lake').load(query_hss)\n",
    "\n",
    "# Transform\n",
    "def transFields(df_hss: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df1_field = df_hss[df_hss['createdMG'].notnull()]\n",
    "    df2_field = df1_field[df1_field['QC_Flag'].isnull()]\n",
    "\n",
    "    df_field_MAT = df2_field[df2_field['OBS_observationRefCd'] == 'MAT']\n",
    "    df_field_YLD = df2_field[df2_field['OBS_observationRefCd'] == 'YLD']\n",
    "\n",
    "    # QC maturity date\n",
    "    df_field_MAT = df_field_MAT[df_field_MAT['OBS_numValue'] > 90]\n",
    "\n",
    "    df_field_MAT.set_index('plot_id', drop=False, inplace=True)\n",
    "    df_field_YLD.set_index('plot_id', drop=False, inplace=True)\n",
    "\n",
    "    df = pd.merge(df_field_MAT,\n",
    "                  df_field_YLD['OBS_numValue'],\n",
    "                  left_index=True,\n",
    "                  right_index=True)\n",
    "\n",
    "    df.set_index('FIELD_uniqueName', inplace=True)\n",
    "\n",
    "    df = df.iloc[:, [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 17, 12]]\n",
    "\n",
    "    df.rename(\n",
    "        columns={\"OBS_numValue_x\": \"MAT\", \"OBS_numValue_y\": \"YLD\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    df['createdMG'] = df['createdMG'].astype('float')\n",
    "    df['MG'] = df['createdMG'].apply(np.round_).astype('int')\n",
    "    df['MAT'] = df['MAT'].astype('int')\n",
    "\n",
    "    df['HARV'] = (df['FIELD_harvestDate'] -\n",
    "                  df['FIELD_plantingDate']).astype('timedelta64[D]')\n",
    "\n",
    "    # Correcting when MAT > Harvest\n",
    "    df['HARV'][df['MAT'] > df['HARV']] = df['MAT']\n",
    "\n",
    "    # Removing duplicated values, YM cases\n",
    "    df = df.loc[-df['plot_id'].duplicated()]\n",
    "\n",
    "    df['R1_DSSAT'] = np.nan\n",
    "    df['R2_DSSAT'] = np.nan\n",
    "    df['R3_DSSAT'] = np.nan\n",
    "    df['R5_DSSAT'] = np.nan\n",
    "    df['R7_DSSAT'] = np.nan\n",
    "    df['R8_DSSAT'] = np.nan\n",
    "    df['YLD_DSSAT'] = np.nan\n",
    "    df['pars_DSSAT'] = np.nan\n",
    "    df['AE_defPars'] = np.nan\n",
    "    df['AE_calPars'] = np.nan\n",
    "    df['pars_DSSAT'] = df.pars_DSSAT.astype('object')\n",
    "\n",
    "    return df\n",
    "\n",
    "# DSSAT Calibration\n",
    "def DSSAT_CalPlots(fld):\n",
    "    try:\n",
    "\n",
    "        # Field crop level\n",
    "        print('Processing Field unique name: ' + fld)\n",
    "        df_field = df[df.index == fld]\n",
    "\n",
    "        pd = df_field['FIELD_plantingDate'][0].replace(tzinfo=None)\n",
    "        hd = df_field['FIELD_harvestDate'][0].replace(tzinfo=None)\n",
    "        lon, lat = df_field['FIELD_field_longitude'][0], df_field['FIELD_field_latitude'][0]\n",
    "        st = (pd - timedelta(days=30)).date()\n",
    "        \n",
    "        # Weather retrieval\n",
    "        \n",
    "        query_TWC = f\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            read_parquet('s3://s3-latam-gmd-coe/WEATHER/TWC_brazil_soybeans.parquet')\n",
    "        WHERE\n",
    "            lat = '{lat}' AND lon = '{lon}' AND date >= '{st.strftime('%Y-%m-%d')}' AND date <= '{hd.strftime('%Y-%m-%d')}' \n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        df_wth = con.execute(query_TWC).df()      \n",
    "        df_wth['DOY'] = df_wth['date'].apply(lambda x: int(x.strftime('%j')))\n",
    "\n",
    "        # Incident solar radiation (Rs_in)\n",
    "        rad = np.pi/180  # Radians to degrees\n",
    "        gra = 180/np.pi  # Degrees to radians\n",
    "\n",
    "        Ko = 37.63*(1+(0.033*(np.cos(rad*((360*df_wth['DOY'])/365)))))\n",
    "        ds = 23.45*np.sin(rad*(360*(df_wth['DOY']-80)/365))\n",
    "        hn = (np.arccos(-np.tan(rad*df_wth['lat'][0])*np.tan(rad*ds)))*gra\n",
    "        Qo = Ko*(rad*hn*np.sin(rad*df_wth['lat'][0])*np.sin(rad*ds) +\n",
    "                 np.cos(rad*df_wth['lat'][0])*np.cos(rad*ds)*np.sin(rad*hn))\n",
    "\n",
    "        df_wth['Rs_in'] = 0.16*Qo * \\\n",
    "            ((df_wth['max_temperature'])-(df_wth['min_temperature']))**0.5\n",
    "\n",
    "        WTH_columns = [\n",
    "            'date',\n",
    "            'min_temperature',\n",
    "            'max_temperature',\n",
    "            'total_precipitation',\n",
    "            'Rs_in',\n",
    "            'avg_relative_humidity',\n",
    "        ]\n",
    "        # Create a WeatherData instance\n",
    "        WTH_DATA = WeatherData(df_wth.loc[:, WTH_columns],\n",
    "                               variables={\n",
    "                                   'min_temperature': 'TMIN',\n",
    "                                   'max_temperature': 'TMAX',\n",
    "                                   'total_precipitation': 'RAIN',\n",
    "                                   'Rs_in': 'SRAD',\n",
    "                                   'avg_relative_humidity': 'RHUM',\n",
    "        })\n",
    "\n",
    "        query_elev =f\"\"\"\n",
    "        SELECT \n",
    "            elevation \n",
    "        FROM \n",
    "            read_parquet('s3://s3-latam-gmd-coe/FIELDS/FIELD_brazil_soybeans.parquet')\n",
    "        WHERE\n",
    "            FIELD_field_latitude = {lat} AND FIELD_field_longitude = {lon}\n",
    "        \"\"\"\n",
    "\n",
    "        elev = con.execute(query_elev).df().squeeze()\n",
    "\n",
    "        # Create a WheaterStation instance\n",
    "        wth = WeatherStation(WTH_DATA, {\n",
    "            'ELEV': elev,\n",
    "            'LAT': lat,\n",
    "            'LON': lon,\n",
    "            'INSI': 'dpoes'\n",
    "        })\n",
    "\n",
    "        print('Weather for Field ' + fld + ' was obtained')\n",
    "        \n",
    "        # Soil retrieval\n",
    "        query_soil = f\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            read_parquet('s3://s3-latam-gmd-coe/SOIL/ISRIC_brazil_soybeans.parquet')\n",
    "        WHERE\n",
    "            h3_index_10 = '{h3.geo_to_h3(lat=lat, lng=lon, resolution=10)}'\n",
    "        \"\"\"\n",
    "\n",
    "        df_soil = con.execute(query_soil).df()\n",
    "        # Creating a soil profile instance\n",
    "        soilprofile = SoilProfile(\n",
    "            pars={\n",
    "                'SALB': 0.16,  # Albedo\n",
    "                'SLU1': 6,  # Stage 1 Evaporation (mm)\n",
    "                'SLPF': 0.8,  # Soil fertility factor\n",
    "                'lon': lon,\n",
    "                'lat': lat,\n",
    "            })\n",
    "\n",
    "        layers = [\n",
    "            SoilLayer(\n",
    "                0, {\n",
    "                    'SLCL': df_soil['clyppt_depth_0cm'][0],\n",
    "                    'SLSI': df_soil['sltppt_depth_0cm'][0]\n",
    "                }),\n",
    "            SoilLayer(\n",
    "                5, {\n",
    "                    'SLCL': df_soil['clyppt_depth_5cm'][0],\n",
    "                    'SLSI': df_soil['sltppt_depth_5cm'][0]\n",
    "                }),\n",
    "            SoilLayer(\n",
    "                15, {\n",
    "                    'SLCL': df_soil['clyppt_depth_15cm'][0],\n",
    "                    'SLSI': df_soil['sltppt_depth_15cm'][0]\n",
    "                }),\n",
    "            SoilLayer(\n",
    "                30, {\n",
    "                    'SLCL': df_soil['clyppt_depth_30cm'][0],\n",
    "                    'SLSI': df_soil['sltppt_depth_30cm'][0]\n",
    "                }),\n",
    "            SoilLayer(\n",
    "                60, {\n",
    "                    'SLCL': df_soil['clyppt_depth_60cm'][0],\n",
    "                    'SLSI': df_soil['sltppt_depth_60cm'][0]\n",
    "                }),\n",
    "            SoilLayer(\n",
    "                100, {\n",
    "                    'SLCL': df_soil['clyppt_depth_100cm'][0],\n",
    "                    'SLSI': df_soil['sltppt_depth_100cm'][0]\n",
    "                })\n",
    "        ]\n",
    "\n",
    "        for layer in layers:\n",
    "            soilprofile.add_layer(layer)\n",
    "\n",
    "        print('Soil profile for Field ' + fld + ' was obtained')\n",
    "        # Plot cultivar level\n",
    "        df_field['DSSATcultivar'] = df_field['MG'].apply(\n",
    "            lambda x: '9900' + f'{x:02d}')\n",
    "        df_field['CSDL'] = -0.321 * df_field['createdMG'] + 14.51\n",
    "\n",
    "        pars_name = ['EM-FL', 'FL-SH', 'FL-SD', 'SD-PM']\n",
    "\n",
    "        for i in range(len(df_field)):\n",
    "\n",
    "            try:\n",
    "                print('Running DSSAT for cultivar ' +\n",
    "                      df_field['DSSATcultivar'][i])\n",
    "                # DSSAT simulation\n",
    "                pars = [\n",
    "                    crop.cultivar[df_field['DSSATcultivar'][i]].get(par)\n",
    "                    for par in pars_name\n",
    "                ]\n",
    "                crop.cultivar[df_field['DSSATcultivar']\n",
    "                              [i]]['CSDL'] = df_field['CSDL'][i]\n",
    "\n",
    "                man = Management(cultivar=df_field['DSSATcultivar'][i],\n",
    "                                 planting_date=pd,\n",
    "                                 sim_start=WTH_DATA.index[0],\n",
    "                                 harvest='R',\n",
    "                                 irrigation='N')\n",
    "\n",
    "                man.simulation_controls['SYMBI'] = 'Y'\n",
    "                man.simulation_controls['SMODEL'] = 'CRGRO'\n",
    "                man.simulation_controls['NITRO'] = 'Y'\n",
    "                man.harvest_details['table']['HDATE'][0] = hd.strftime('%y%j')\n",
    "\n",
    "                obs = df_field['MAT'][i]\n",
    "                # DSSAT calibration\n",
    "                print('Calibrating DSSAT for cultivar ' +\n",
    "                      df_field['DSSATcultivar'][i])\n",
    "\n",
    "                # DSSAT run\n",
    "                dssat = DSSAT()\n",
    "                dssat.setup()\n",
    "\n",
    "                dssat.run(\n",
    "                    soil=soilprofile,\n",
    "                    weather=wth,\n",
    "                    crop=crop,\n",
    "                    management=man,\n",
    "                )\n",
    "\n",
    "                df_out = dssat.output['PlantGro']\n",
    "                YLD_e = df_out['GWAD'].iloc[-1] / 100  # qq/ha\n",
    "\n",
    "                # Fixing the error of 'None' value when R8 is not computed\n",
    "                MAT_day = df_out[df_out.GSTD == 8].first_valid_index()\n",
    "                MAT_day = df_out[df_out.GSTD == 3].first_valid_index(\n",
    "                ) if MAT_day is None else MAT_day\n",
    "\n",
    "                MAT_e = (MAT_day - pd).days\n",
    "\n",
    "                AE_def = abs(obs - MAT_e)\n",
    "\n",
    "                print('Absolute error defaut parameters = ' + str(AE_def))\n",
    "\n",
    "                # Objective function\n",
    "                def DSSAT_obj(pars):\n",
    "\n",
    "                    crop.cultivar[df_field['DSSATcultivar']\n",
    "                                  [i]]['EM-FL'] = pars[0]\n",
    "                    crop.cultivar[df_field['DSSATcultivar']\n",
    "                                  [i]]['FL-SH'] = pars[1]\n",
    "                    crop.cultivar[df_field['DSSATcultivar']\n",
    "                                  [i]]['FL-SD'] = pars[2]\n",
    "                    crop.cultivar[df_field['DSSATcultivar']\n",
    "                                  [i]]['SD-PM'] = pars[3]\n",
    "\n",
    "                    dssat.run(\n",
    "                        soil=soilprofile,\n",
    "                        weather=wth,\n",
    "                        crop=crop,\n",
    "                        management=man,\n",
    "                    )\n",
    "\n",
    "                    df_out = dssat.output['PlantGro']\n",
    "                    YLD_e = df_out['GWAD'].iloc[-1] / 100  # qq/ha\n",
    "\n",
    "                    MAT_day = df_out[df_out.GSTD == 8].first_valid_index()\n",
    "                    MAT_day = df_out[df_out.GSTD == 3].first_valid_index(\n",
    "                    ) if MAT_day is None else MAT_day\n",
    "\n",
    "                    MAT_e = (MAT_day - pd).days\n",
    "\n",
    "                    print('Absolute error = ' + str(abs(obs - MAT_e)) +\n",
    "                          '\\nField unique name = ' + str(fld) + '\\nPlot ID = ' +\n",
    "                          str(df_field['plot_id'][i]))\n",
    "\n",
    "                    return abs(obs - MAT_e)\n",
    "\n",
    "                DSSAT_cal = gp_minimize(\n",
    "                    func=DSSAT_obj,\n",
    "                    dimensions=bounds,\n",
    "                    acq_func='EI',\n",
    "                    xi=3,\n",
    "                    initial_point_generator='lhs',\n",
    "                    acq_optimizer='sampling'\n",
    "                )\n",
    "\n",
    "                idx_func = np.where(\n",
    "                    DSSAT_cal['func_vals'] == DSSAT_cal['func_vals'].min())[0].tolist()\n",
    "                AE_cal = DSSAT_cal['func_vals'][idx_func[0]]\n",
    "                pars_cal = [DSSAT_cal['x_iters'][index] for index in idx_func]\n",
    "\n",
    "                # round parameters\n",
    "                pars_cal = [[np.round(float(i), 2) for i in nested]\n",
    "                            for nested in pars_cal]\n",
    "                print(pars_cal)\n",
    "\n",
    "                df_field.iat[i, df_field.columns.get_loc(\n",
    "                    'pars_DSSAT')] = pars_cal\n",
    "                df_field['AE_defPars'][i] = AE_def\n",
    "                df_field['AE_calPars'][i] = AE_cal\n",
    "\n",
    "                # Updating with the calibrated parameters\n",
    "                crop.cultivar[df_field['DSSATcultivar']\n",
    "                              [i]]['EM-FL'] = pars_cal[0][0]\n",
    "                crop.cultivar[df_field['DSSATcultivar']\n",
    "                              [i]]['FL-SH'] = pars_cal[0][1]\n",
    "                crop.cultivar[df_field['DSSATcultivar']\n",
    "                              [i]]['FL-SD'] = pars_cal[0][2]\n",
    "                crop.cultivar[df_field['DSSATcultivar']\n",
    "                              [i]]['SD-PM'] = pars_cal[0][3]\n",
    "\n",
    "                # DSSAT re-run with calibrated parameters\n",
    "                dssat.run(\n",
    "                    soil=soilprofile,\n",
    "                    weather=wth,\n",
    "                    crop=crop,\n",
    "                    management=man,\n",
    "                )\n",
    "\n",
    "                df_out = dssat.output['PlantGro']\n",
    "\n",
    "                R1 = (df_out[df_out.GSTD == 1].first_valid_index() - pd).days\n",
    "                R2 = (df_out[df_out.GSTD == 2].first_valid_index() - pd).days\n",
    "                R3 = (df_out[df_out.GSTD == 3].first_valid_index() - pd).days\n",
    "                R5 = (df_out[df_out.GSTD == 5].first_valid_index() - pd).days\n",
    "                R7 = (df_out[df_out.GSTD == 7].first_valid_index() - pd).days\n",
    "                R8 = (df_out[df_out.GSTD == 8].first_valid_index() - pd).days\n",
    "                YLD_e = df_out['GWAD'].iloc[-1] / 100  # qq/ha\n",
    "\n",
    "                print('R1 estimated = ' + str(R1) + ' dap\\n' +\n",
    "                      'R2 estimated = ' + str(R2) + ' dap\\n' +\n",
    "                      'R3 estimated = ' + str(R3) + ' dap\\n' +\n",
    "                      'R5 estimated = ' + str(R5) + ' dap\\n' +\n",
    "                      'R7 estimated = ' + str(R7) + ' dap\\n' +\n",
    "                      'R8 estimated = ' + str(R8) + ' dap' + '\\nR8 observed = ' +\n",
    "                      str(df_field['MAT'][i]) + ' dap' + '\\nYLD estimated = ' +\n",
    "                      str(YLD_e) + ' qq/ha' + '\\nYLD observed = ' +\n",
    "                      str(df_field['YLD'][i]) + ' qq/ha')\n",
    "\n",
    "                df_field['R1_DSSAT'][i] = R1\n",
    "                df_field['R2_DSSAT'][i] = R2\n",
    "                df_field['R3_DSSAT'][i] = R3\n",
    "                df_field['R5_DSSAT'][i] = R5\n",
    "                df_field['R7_DSSAT'][i] = R7\n",
    "                df_field['R8_DSSAT'][i] = R8\n",
    "                df_field['YLD_DSSAT'][i] = YLD_e\n",
    "\n",
    "                dssat.close()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    return df_field\n",
    "\n",
    "# Load\n",
    "def loadDSSATpars(calibration: list, crop: str, regn: str) -> None: \n",
    "    \n",
    "    df_cal = pd.concat(calibration)\n",
    "    df_cal = df_cal[df_cal.R8_DSSAT.notna()]\n",
    "\n",
    "    df_cal.drop(['MG', 'YLD_DSSAT', 'AE_defPars',\n",
    "                    'AE_calPars', 'CSDL'], axis=1, inplace=True)\n",
    "\n",
    "    df_cal = df_cal.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 12, 19, 20]]\n",
    "    df_cal = df_cal.reset_index()\n",
    "\n",
    "    df_cal[['FIELD_uniqueName', 'FIELD_NAME', 'commercialName',\n",
    "                       'protocolNumber', 'plot_id', 'pars_DSSAT', 'DSSATcultivar']] = \\\n",
    "    df_cal[['FIELD_uniqueName', 'FIELD_NAME', 'commercialName',\n",
    "                           'protocolNumber', 'plot_id', 'pars_DSSAT', 'DSSATcultivar']].astype('string')\n",
    "\n",
    "    CSWconnect('bcs-market-dev-lake').save(df_cal, f'latam_datasets.dssat_{regn}_{crop}', append=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # N computers/hardware tiers\n",
    "    job = sys.argv[1] \n",
    "    n_hards = sys.argv[2] \n",
    "    \n",
    "    # Creating bounds\n",
    "    crop = Crop('Soybean')\n",
    "\n",
    "    # Creating bounds\n",
    "    bounds = [\n",
    "        (crop.cultivar['999991']['EM-FL'], crop.cultivar['999992']['EM-FL']),\n",
    "        (crop.cultivar['999991']['FL-SH'], crop.cultivar['999992']['FL-SH']),\n",
    "        (crop.cultivar['999991']['FL-SD'], crop.cultivar['999992']['FL-SD']),\n",
    "        (crop.cultivar['999991']['SD-PM'], crop.cultivar['999992']['SD-PM']),\n",
    "    ]\n",
    "\n",
    "    # Some configs\n",
    "    aws_access_key_id=os.environ['aws_key']\n",
    "    aws_secret_access_key=os.environ['aws_secret']\n",
    "    aws_region='us-east-2'\n",
    "\n",
    "    # Connect duckdb\n",
    "    con = duckdb.connect()\n",
    "    con.execute(f\"\"\"\n",
    "            INSTALL httpfs;\n",
    "            LOAD httpfs;\n",
    "            SET s3_region='us-east-2';\n",
    "            SET s3_access_key_id='{aws_access_key_id}';\n",
    "            SET s3_secret_access_key='{aws_secret_access_key}';\n",
    "            SET threads TO 20;\n",
    "            \"\"\")\n",
    "\n",
    "    # HSS \n",
    "    df_hss = getFields(crop = 'soybeans', regn = 'brazil')\n",
    "\n",
    "    # Dataframe transformed\n",
    "    df = transFields(df_hss)\n",
    "\n",
    "    # Defining the fields\n",
    "    fields = df.index.unique()\n",
    "       \n",
    "    # Number of cores in one machine\n",
    "    n_cores = 25\n",
    "        \n",
    "    # Horizontal scaling for n hardwares\n",
    "    fields_hard = np.array_split(fields, n_hards)\n",
    "   \n",
    "    # Parallel processing for n_cores\n",
    "    with Pool(n_cores) as pool:\n",
    "        calibration = pool.map(DSSAT_CalPlots, fields_hard[job])\n",
    "       \n",
    "\n",
    "    loadDSSATpars(calibration, 'soybeans', 'brazil')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc60385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domino runs\n",
    "from domino import Domino\n",
    "import os\n",
    "\n",
    "domino = Domino(\n",
    "    \"Field_Trialing_LATAM/FieldTrialing_Latam\",\n",
    "    api_key=os.environ[\"DOMINO_USER_API_KEY\"],\n",
    "    host=os.environ[\"DOMINO_API_HOST\"],\n",
    ")\n",
    "\n",
    "n_jobs = 35\n",
    "\n",
    "for i in range(n_jobs+1):\n",
    "    domino_run = domino.runs_start(\n",
    "        [\"/WaterBalance/DSSATcal.py\", str(i), str(n_jobs)], title=\"Scaling DSSAT calibration\"\n",
    "    )\n",
    "\n",
    "run_status = domino.runs_status(domino_run.get(\"runId\"))\n",
    "\n",
    "print(run_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de38378f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T11:57:25.653349Z",
     "start_time": "2023-03-03T11:56:43.286686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Domino runs\n",
    "from domino import Domino\n",
    "import os\n",
    "\n",
    "\n",
    "domino = Domino(\n",
    "    \"Field_Trialing_LATAM/FieldTrialing_Latam\",\n",
    "    api_key=os.environ[\"DOMINO_USER_API_KEY\"],\n",
    "    host=os.environ[\"DOMINO_API_HOST\"],\n",
    ")\n",
    "\n",
    "n_jobs = 35\n",
    "\n",
    "for i in range(n_jobs+1):\n",
    "    domino_run = domino.runs_start(\n",
    "        [\"python\", \"-c\", \"print('Job run number:'\" + str(i) + \")\"], title=\"Scalling Jobs\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c154144e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T20:47:48.395595Z",
     "start_time": "2023-03-02T20:47:48.301519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '640107abef9b7a29a75faa46', 'projectId': '61ae4449f7cecf452b62e9c5', 'number': 10758, 'startingUserId': '631f2855f48f7f33892de7ae', 'queued': 1677789099986, 'started': 1677789666479, 'completed': 1677789680389, 'status': 'Failed', 'commitId': 'a70ddff821302b92a0a1e8bd46f54f03a230688d', 'startingScheduledRunId': None, 'outputCommitId': '75f8d7801437781f6f8495ae33be9956ddea906a', 'title': 'Scalling Jobs', 'publiclyVisible': False, 'isArchived': False, 'postProcessedTimestamp': 1677789682697, 'diagnosticStatistics': None, 'isCompleted': True, 'hardwareTierId': 'r5a8x', 'environmentId': '61ae494012c791680f46b4a7', 'environmentRevisionId': '63360b9cf48f7f33893e7acb', 'repositories': [{'id': '61ae44aaf7cecf452b62eab0', 'name': 'Analysis_scripts', 'ref': '(Default branch)', 'serviceProvider': 'githubEnterprise', 'startingCommitId': '45f03e820dd9aae6ac689085675e30d69ce841d5', 'finishedCommitId': '45f03e820dd9aae6ac689085675e30d69ce841d5', 'uri': 'https://github.platforms.engineering/Latam-FT/Analysis_scripts.git', 'startingBranch': 'master', 'finishedBranch': 'master'}, {'id': '61ae44f22cab120724ba6991', 'name': 'Latam-FT_IntactaPlus', 'ref': '(Default branch)', 'serviceProvider': 'githubEnterprise', 'startingCommitId': '0dc1c0e61aff975bff629b06ff1e5227eb08e946', 'finishedCommitId': '0dc1c0e61aff975bff629b06ff1e5227eb08e946', 'uri': 'https://github.platforms.engineering/Latam-FT/IntactaPlus.git', 'startingBranch': 'main', 'finishedBranch': 'main'}, {'id': '6220ceb87da8471691ea2821', 'name': 'YieldMap_Utilities', 'ref': '(Default branch)', 'serviceProvider': 'githubEnterprise', 'startingCommitId': '52a18e2b58ad9ed82885aaf2b8aca96d5c5498d6', 'finishedCommitId': '52a18e2b58ad9ed82885aaf2b8aca96d5c5498d6', 'uri': 'https://github.platforms.engineering/Latam-FT/YieldMap_Utilities.git', 'startingBranch': 'master', 'finishedBranch': 'master'}, {'id': '61ae44ddf7cecf452b62eb37', 'name': 'Environmental_scripts', 'ref': '(Default branch)', 'serviceProvider': 'githubEnterprise', 'startingCommitId': '05db17b43c7ff7d21ac46041ed936da96b50194f', 'finishedCommitId': '05db17b43c7ff7d21ac46041ed936da96b50194f', 'uri': 'https://github.platforms.engineering/Latam-FT/Environmental_scripts.git', 'startingBranch': 'master', 'finishedBranch': 'master'}, {'id': '61ae4448f7cecf452b62e9c2', 'name': 'DataWorkflow', 'ref': '(Default branch)', 'serviceProvider': 'githubEnterprise', 'startingCommitId': 'ec03e321af5de628b190ec703c44d018407fa8db', 'finishedCommitId': 'ec03e321af5de628b190ec703c44d018407fa8db', 'uri': 'https://github.platforms.engineering/Latam-FT/DataWorkflow.git', 'startingBranch': 'master', 'finishedBranch': 'master'}], 'notebookName': None, 'runQueueingInformation': None, 'datasetMounts': [{'containerPath': '/mnt/data/FieldTrialing_Latam', 'datasetId': '62b7bd90e7db4e34fd45dd0d', 'snapshotId': '62b7bda6e7db4e34fd461dff', 'isReadOnly': False, 'resourceId': 'f47e9112-e126-4291-9d87-d763abb0945a', 'resourcePath': 'f47e9112-e126-4291-9d87-d763abb0945a'}], 'containerExitCode': 1, 'autoSyncSettings': None}\n"
     ]
    }
   ],
   "source": [
    "run_status = domino.runs_status(domino_run.get(\"runId\"))\n",
    "\n",
    "print(run_status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
